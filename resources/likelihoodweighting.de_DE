noSuchKeyException=Es gibt keine Ressource f\u000ferr Eintrag {0}
iconNotFound=Icon "{0}" not found

### keys ###

introTOC=Einleitung
firstIterationTOC=Erste Iteration
outroTOC=Zusammenfassung

of=von
normValue=Normalisierter Wert

description=Bayessche Netze werden dazu genutzt, um Abhängigkeiten zwischen Zufallsvariablen zu modellieren und Wahrscheinlichkeiten von Ereignissen zu berechnen. \nExakte Inferenz, d.h. die Bestimmung einer bedingten Wahrscheinlichkeit, ist in solchen Netzen allerdings ein NP-hartes Problem, weswegen man mit Sampling Methoden zumindest eine annähernd exakte Inferenz erreichen will.\nHier wird Gibbs Sampling genutzt, ein Markov Chain Monte Carlo Algorithmus. Dieser beginnt in einem willkürlichen Zustand und erzeugt jede Iteration einen neuen Zustand, indem ein Wert durch ein zufälliges Sample einer Zufallsvariable erzeugt wird. \nDie Wahrscheinlichkeit einen bestimmten Wert zu samplen hängt dabei von den vorher festgeletgten bedingten Wahrscheinlichkeiten der Zufallsvariablen ab.

intro=Der gerichtete Graph in diesem Beispiel visualisiert das gewählte Bayessche Netz, wobei die Knoten die Zufallsvariablen und die Kanten die Abhängigkeiten darstellen. \nDie unbekannten Zufallsvariablen werden anhand der berechneten Wahrscheinlichkeit einer Zufallsstichprobe unterzogen (gesamplet) und erhalten damit einen eindeutigen Wert.\nDurch das Zählen der Samples wird damit die a-posteriori Wahrscheinlichkeit einer unbekannten Zufallsvariable über die Iterationen mit der Zeit angenähert, was auch das Ziel des Sampling-Algorithmus ist.

outro=Wie wir sehen konnten hat der Algorithmus in anbetracht des Bayesschen Netzes für X ein nachvollziehbares Ergebnis geliefert. \nEs lässt sich zeigen, dass diese Annäherung in einem stationären Zustand der Markov-Kette konvergiert, welcher der echte Wahrscheinlichkeitsverteilung entspricht. \nWenn man also nur lange genug samplet, lässt sich ein Bias durch die Diskretisierung der Ergebnisse minimieren. \nNachteil ist jedoch das dieser Algorithmus alle bedingten Wahrscheinlichkeiten gegeben haben muss, welche oft nicht zur Verfügung stehen.

firstIteration=1. Iteration

line0=Starte neue Iteration

line1=Setze Gewichtung zurück auf 1.0

line2=Wähle eine Zufallsvariable aus dem Netz aus

line3=Wenn die Zufallsvariable eine Evidenzvariable ist ...

line4=... dann multipliziere ihre a-posteriori Wahrscheinlichkeit zur Gewichtung dazu

line5=... ansonsten ...

line6=... sample den Wert basierend auf der bedingten Wahrscheinlichkeit

line7=Speichere die Gewichtung für jede Zufallsvariable abhängig von ihrem Wert

line8=Normalisiere die Werte und gib sie zurück


wrong_asw=falsche Antwort\n

right_asw=richtige Antwort\n

q1_text=Welche Zufallsvariablen haben von Anfang an Werte?

q1_asw1=Nur die Sample Variablen

q1_asw2=Alle Zufallsvariablen

q1_asw3=Nur die Evidenzvariablen

q1_fb=Nur die Evidenzvariablen haben am Anfang Werte
