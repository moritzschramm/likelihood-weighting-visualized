noSuchKeyException=There is no resource for key {0}
iconNotFound=Icon "{0}" not found

### keys ###

introTOC=Intro
firstIterationTOC=1st iteration
outroTOC=Summary

of=of
normValue=Normalized value

description=Bayesian networks are used to model dependencies between random variables and to calculate probabilities of events. \nDeveloping exact inference, i.e determine a conditional probability, is a NP-hard problem for bayesian networks. For this reason sampling methods are used to approximate the exact inference. \nHere we use Gibbs Sampling, a Markov Chain Monte Carlo algorithm. It starts in a random state and generates a new state based on a random sample of a random variable for each iteration. \nThe probability to sample a specific value depends on the conditional propabilities that were set at the beginning.

intro=A directed graph is used to visualize the bayessian network so that the vertices represent the random variables and the edges represent the conditions. \nThe unknown random variables (non-evidence variables) will be random-sampled based on the computed probabilities and receive a value of true or false.\nBy counting the numbers of samples of true and false for each non-evidence variable and normalizing them at the end, the algorithm approximates the a-posteriori probability by time over each iteration.

outro=As we can see, the algorithm produces an relatable result for X in consideration of the bayessian network. \nIt can be shown that the approximation converges in a stationary state of the markov-chain which corresponds to the real probability distribution. \nTherefore the bias of the discretization (sampling) vanishes with respect to the iterations taken. \nThe downside of this algorithm is that it needs all conditional probabilities which are often not available.



line0=Begin new iteration

line1=Reset weight to 1.0

line2=Choose a random variable

line3=If the random variable is an evidence variable...

line4... then multiply its a-posteriori probability with the weight

line5=... or else, ...

line6=sample a value based on the conditional probability

line7=Store the weight for every sample variable depending on its value

line8=Normalise the result and return it


wrong_asw=wrong answer\n

right_asw=right answer\n

q1_text=At the beginning, which random variables have values?

q1_asw1=Only sample variables

q1_asw2=All random variables

q1_asw3=Only evidence variables

q1_fb=Only evidence variables have values at the beginning
